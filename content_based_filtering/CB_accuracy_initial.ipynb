{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def cosine_similarity_n_space(m1, m2, batch_size=100):\n",
    "    assert m1.shape[1] == m2.shape[1]\n",
    "    ret = np.ndarray((m1.shape[0], m2.shape[0]), dtype=np.float32)\n",
    "    for row_i in range(0, int(m1.shape[0] / batch_size) + 1):\n",
    "        start = row_i * batch_size\n",
    "        end = min([(row_i + 1) * batch_size, m1.shape[0]])\n",
    "        if end <= start:\n",
    "            break \n",
    "        rows = m1[start: end]\n",
    "        sim = cosine_similarity(rows, m2) # rows is O(1) size\n",
    "        ret[start: end] = sim\n",
    "    return ret\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = r'spot_final.json'\n",
    "df = pd.read_json(file_path)\n",
    "\n",
    "# Select relevant columns for content-based filtering\n",
    "numerical_features = ['acousticness', 'danceability', 'duration_ms', 'energy', 'instrumentalness', 'loudness', 'liveness', 'speechiness', 'time_signature', 'key', 'valence', 'tempo']\n",
    "\n",
    "# Fill missing values in numerical columns with their mean values\n",
    "df[numerical_features] = df[numerical_features].fillna(df[numerical_features].mean())\n",
    "\n",
    "# Normalize numerical features to have values between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "numerical_features_matrix_sampled = df[numerical_features].values\n",
    "numerical_features_sparse_sampled = sparse.csr_matrix(numerical_features_matrix_sampled)\n",
    "numerical_similarity_sampled = cosine_similarity_n_space(numerical_features_sparse_sampled,numerical_features_sparse_sampled, batch_size= 100)\n",
    "\n",
    "#reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a mapping of track URIs to their respective indices in the DataFrame\n",
    "track_uri_to_index_sampled = pd.Series(df.index, index=df['track_uri'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to get top 5 songs\n",
    "\n",
    "# Function to get song recommendations based on song title for the unique playlists\n",
    "def get_recommendations_sampled(song_title, numerical_similarity_sampled):\n",
    "    # Get the index of the song\n",
    "    song_index = track_uri_to_index_sampled[song_title]\n",
    "    # print(song_index)\n",
    "    \n",
    "    # Get the pairwise similarity scores of all songs with the given song\n",
    "    sim_scores = list(enumerate(numerical_similarity_sampled[song_index]))\n",
    "    \n",
    "    # Sort the songs based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top 5 most similar songs\n",
    "    sim_scores = sim_scores[1:6]  # Exclude the first song (itself)\n",
    "    \n",
    "    # Get the indices of the similar songs\n",
    "    song_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Return the top 5 similar songs\n",
    "    return df['track_uri'].iloc[song_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_sampled(playlist_df):\n",
    "    # Get the songs in the playlist\n",
    "    songs_in_playlist = playlist_df['track_uri'].values\n",
    "\n",
    "    # Initialize variables to store accuracy for this playlist and the total number of correct recommendations\n",
    "    playlist_accuracy = 0\n",
    "    total_correct_recommendations = 0\n",
    "\n",
    "    # Set to keep track of recommended songs\n",
    "    recommended_songs_set = set()\n",
    "\n",
    "    # Iterate through each song in the playlist\n",
    "    for song_uri in songs_in_playlist:\n",
    "        # Recommend the same number as in the playlist, excluding already recommended songs\n",
    "        recommended_songs = get_recommendations_sampled(song_uri, numerical_similarity_sampled)\n",
    "        recommended_songs = [song for song in recommended_songs if song not in recommended_songs_set]\n",
    "\n",
    "        # Calculate the number of correct recommendations (intersection between recommended and actual songs)\n",
    "        correct_recommendations = len(set(songs_in_playlist) & set(recommended_songs))\n",
    "        total_correct_recommendations += correct_recommendations\n",
    "\n",
    "        # Update the set of recommended songs\n",
    "        recommended_songs_set.update(recommended_songs)\n",
    "\n",
    "    # Calculate accuracy for this playlist\n",
    "    playlist_accuracy = total_correct_recommendations / len(songs_in_playlist)\n",
    "\n",
    "    return playlist_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy for sampled playlists: 0.11638808995189474\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'playlist_uris' column to tuples\n",
    "df['playlist_uris'] = df['playlist_uris'].apply(tuple)\n",
    "\n",
    "# Explode the DataFrame to have one row for each playlist URI in the lists\n",
    "exploded_df = df.explode('playlist_uris')\n",
    "\n",
    "# Group the exploded DataFrame by 'playlist_uris'\n",
    "grouped_df = exploded_df.groupby('playlist_uris')\n",
    "\n",
    "# Initialize variables to store overall accuracy and the number of playlists processed for the playlists\n",
    "overall_accuracy_sampled = 0 \n",
    "num_playlists_sampled = 0\n",
    "\n",
    "# Iterate through each unique playlist in the dataset\n",
    "for playlist_uri, playlist_df in grouped_df:\n",
    "    num_playlists_sampled += 1\n",
    "    playlist_accuracy_sampled = calculate_accuracy_sampled(playlist_df)\n",
    "    overall_accuracy_sampled += playlist_accuracy_sampled\n",
    "\n",
    "# Calculate the overall accuracy score for the playlists\n",
    "overall_accuracy_sampled /= num_playlists_sampled\n",
    "\n",
    "print(f\"Overall accuracy for sampled playlists: {overall_accuracy_sampled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11638808995189474"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracy_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_playlists_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
